{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c2f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d12c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5517fb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>second counting input 5 2 which receives inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>extremely low temperature of the chips in cold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>of the basic ammonium salt of the carboxyl ate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>18 u2033 is provided which is axially supporte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>to an u201c inner surface u201d means the surf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                            Content\n",
       "0      2  second counting input 5 2 which receives inter...\n",
       "1      4  extremely low temperature of the chips in cold...\n",
       "2      3  of the basic ammonium salt of the carboxyl ate...\n",
       "3      9  18 u2033 is provided which is axially supporte...\n",
       "4      2  to an u201c inner surface u201d means the surf..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3b289e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    7143\n",
       "8    7102\n",
       "6    6887\n",
       "2    6816\n",
       "1    6756\n",
       "5    6467\n",
       "3    6059\n",
       "9    5961\n",
       "4    5928\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ab4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array( ['(Human Necessities)',\n",
    " '(Performing Operations; Transporting)',\n",
    " '(Chemistry; Metallurgy)',\n",
    " '(Textiles; Paper)',\n",
    " '(Fixed Constructions)',\n",
    " '(Mechanical Engineering; Lightning; Heating; Weapons; Blasting)',\n",
    " '(Physics)',\n",
    " '(Electricity)', \n",
    " '(General tagging of new or cross-sectional technology)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8a56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(data[\"Content\"].to_numpy(),\n",
    "                                                                            data[\"Label\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64290d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53207, 53207, 5912, 5912)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb8be470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['for a multiband operation or in another preferred embodiment the sfc curve such as 25 defines the perimeter of an aperture 33 on the patch 30 fig1 such an aperture contributes significantly to reduce the first resonant frequency of the patch with respect to the solid patch case which significantly contributes to reducing the antenna size said two configurations the sfc slot and the sfc aperture cases can of course be use also with sfc perimeter patch antennas as for instance the one 30 described in fig1 at this point it becomes clear to those skilled in the art what is the scope and spirit of the present invention and that the same sfc geometric principle can be applied in an innovative way to all the well known prior art configurations more examples are given in fig1 16 17 and 18 fig1 describes another preferred embodiment of an sfc antenna it consists on an aperture antenna said aperture being characterized by its sfc perimeter said aperture being impressed over a conducting ground plane or ground counterpoise 34 said ground plane of ground counterpoise consisting for example on a wall of a waveguide or cavity resonator or a part of the structure of a motor vehicle such as a car a lorry an airplane or a tank the aperture can be fed by any of the conventional techniques such as a coaxial cable 11 or a planar microstrip or strip line transmission line to name a few fig1 shows another preferred embodiment where the sfc curves 41 are slotted over a wall of a waveguide 47 of arbitrary cross section this way and slotted waveguide array can be formed with the advantage of the size compressing properties of the sfc curves.',\n",
       "        'may be implemented such a multirange lens is able to alter the peripheral vision and correct astigmatism of the wearer contact lenses such as multirange contact lenses 10 50 and 76 are typically produced as described above by using a transparent material having one refractive index and adjusting curvatures of the zones of the material to form the required different powers transparent materials having variable refractive indices are known in the art such as are used to produce graded index grin lenses and a variable refractive index material may be used to produce a multirange contact lens having powers substantially as described above for lenses 10 50 and 76 all such lenses are assumed to be comprised within the scope of the present invention as will be appreciated by those skilled in the art for any region of a lens using a variable refractive index material the curvature of the zone of the region the base curve and the range and distribution of the refractive index of the material between the zone and the base curve all contribute to the overall power generated for the region it will thus be appreciated that the power of any specific zone the base curve and the transparent material.'],\n",
       "       dtype=object),\n",
       " array([8, 7], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:2], train_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c06051c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc63e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 40000 # max number of words to have in our vocabulary\n",
    "max_length = 250 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7a015a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.embedding.Embedding at 0x28df7ed5c70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d68c4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
    "# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n",
    "\n",
    "# Use the default TextVectorization variables\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
    "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d04b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00923051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b4a0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "counter electrode configuration seen for example in fig5 and 6 that is the product of the design of this invention is a photonic structure when the protruding electrode elements are a metal or metal coated tcm there can also result additional photon density modifications due to plasmonics and photonics effects representative tcms illustratively include indium tin oxide and tin oxy fluoride the structures of fig5 7 are usually termed superstrate solar cells in that they have the light entering the cell through the mechanical support layer a of these figures it is appreciated that an inventive device is operative as either a superstrate cell mechanical support as shown in the accompanying figures or through the substrate cell free surface table i provides some additional superstrate and substrate lccm devices based on employing arrays of unit cell absorber protrusions these may have various spacings l and the ramifications of this in terms of the truncation of the undulations is seen in fig1 a and b computer simulations comparing the performance of these four designs are presented in fig1 17 while the design concepts of this invention can be applied to any absorber and either drift or diffusion collection these computer simulation results of fig1 17 are for.      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 250, 128), dtype=float32, numpy=\n",
       "array([[[-0.04376262,  0.0426993 ,  0.00167274, ...,  0.0314636 ,\n",
       "          0.04202992,  0.00517861],\n",
       "        [ 0.00989809,  0.04891184, -0.00797943, ..., -0.01777726,\n",
       "         -0.02028114,  0.01786032],\n",
       "        [ 0.0125933 , -0.02573659,  0.04071958, ...,  0.04252397,\n",
       "         -0.01512875,  0.03700643],\n",
       "        ...,\n",
       "        [-0.00510817,  0.04110542, -0.01230104, ...,  0.00884434,\n",
       "          0.03181611,  0.04931827],\n",
       "        [-0.00510817,  0.04110542, -0.01230104, ...,  0.00884434,\n",
       "          0.03181611,  0.04931827],\n",
       "        [-0.00510817,  0.04110542, -0.01230104, ...,  0.00884434,\n",
       "          0.03181611,  0.04931827]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92631433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([-0.04376262,  0.0426993 ,  0.00167274,  0.03169236, -0.00236156,\n",
       "        0.0177213 , -0.02621112, -0.02638395, -0.01930866,  0.00377951,\n",
       "       -0.03847653, -0.0264554 , -0.04328701,  0.01010121, -0.02111952,\n",
       "        0.01449213,  0.02950026,  0.013651  , -0.04134249,  0.03763732,\n",
       "       -0.00706149,  0.03954499,  0.04787112, -0.01855935,  0.00706304,\n",
       "        0.01130903,  0.03988916, -0.02587284,  0.041762  , -0.04101966,\n",
       "        0.02751484, -0.04101863,  0.04737658, -0.03562175, -0.04113491,\n",
       "       -0.04723847, -0.0438901 , -0.03894484, -0.00257622,  0.0296664 ,\n",
       "       -0.04703728,  0.03932122, -0.01822954,  0.0367218 , -0.00473329,\n",
       "        0.01149585, -0.01204014, -0.0026757 , -0.0490379 ,  0.01741108,\n",
       "       -0.02374138, -0.0344369 , -0.00132127, -0.00303932, -0.0276466 ,\n",
       "       -0.03618324, -0.01684182, -0.02594539, -0.01679405, -0.02390523,\n",
       "        0.04818306, -0.0097711 , -0.02153879,  0.01583968,  0.03801257,\n",
       "        0.01572362, -0.0463579 , -0.0118014 ,  0.0285165 , -0.04294055,\n",
       "       -0.0441365 ,  0.03815556, -0.00549472,  0.04585078, -0.00829215,\n",
       "        0.02234339,  0.00715651, -0.01789576,  0.00493116,  0.00461612,\n",
       "        0.04271262,  0.02550926, -0.04807756, -0.01546723, -0.03336699,\n",
       "        0.03747212, -0.00939809,  0.02512831,  0.02763448,  0.00041561,\n",
       "       -0.03452053,  0.02523377, -0.04491374,  0.00468426, -0.01316236,\n",
       "       -0.04837035, -0.04944373, -0.01514371,  0.04517489, -0.03520553,\n",
       "       -0.01375431,  0.01581014,  0.02922136, -0.00695617,  0.00452727,\n",
       "       -0.04613646,  0.01714623,  0.02831098,  0.01610761,  0.04139112,\n",
       "       -0.03354795,  0.02991362, -0.03779583, -0.00239829,  0.02887087,\n",
       "        0.00059935,  0.03826977, -0.04948382, -0.02707138, -0.03516153,\n",
       "       -0.00024732,  0.03159869, -0.02445065, -0.0373673 ,  0.01257359,\n",
       "        0.0314636 ,  0.04202992,  0.00517861], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f2ea2",
   "metadata": {},
   "source": [
    "More specifically, we'll be building the following:\n",
    "* **Model 0**: Naive Bayes (baseline)\n",
    "* **Model 1**: Feed-forward neural network (dense model)\n",
    "* **Model 2**: LSTM model\n",
    "* **Model 3**: GRU model\n",
    "* **Model 4**: Bidirectional-LSTM model\n",
    "* **Model 5**: 1D Convolutional Neural Network\n",
    "* **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
    "* **Model 7**: Same as model 6 with 10% of training data\n",
    "\n",
    "Model 0 is the simplest to acquire a baseline which we'll expect each other of the other deeper models to beat.\n",
    "\n",
    "Each experiment will go through the following steps:\n",
    "* Construct the model\n",
    "* Train the model\n",
    "* Make predictions with the model\n",
    "* Track prediction evaluation metrics for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d33b8496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4c6340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 51.91%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32d913ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 5, 2, 2, 7, 1, 1, 8, 5, 8, 7, 2, 5, 3, 4, 8, 2, 7, 7],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051479bd",
   "metadata": {},
   "source": [
    "### Creating an evaluation function for our model experiments\n",
    "\n",
    "We could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score\n",
    "\n",
    "> 🔑 **Note:** Since we're dealing with a classification problem, the above metrics are the most appropriate. If we were working with a regression problem, other metrics such as MAE (mean absolute error) would be a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da02a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff8358e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 51.911366711772665,\n",
       " 'precision': 0.5435636745764952,\n",
       " 'recall': 0.5191136671177267,\n",
       " 'f1': 0.491364899712393}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e84ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
