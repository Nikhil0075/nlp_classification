{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c2f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d12c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5517fb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>second counting input 5 2 which receives inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>extremely low temperature of the chips in cold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>of the basic ammonium salt of the carboxyl ate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>18 u2033 is provided which is axially supporte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>to an u201c inner surface u201d means the surf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                            Content\n",
       "0      2  second counting input 5 2 which receives inter...\n",
       "1      4  extremely low temperature of the chips in cold...\n",
       "2      3  of the basic ammonium salt of the carboxyl ate...\n",
       "3      9  18 u2033 is provided which is axially supporte...\n",
       "4      2  to an u201c inner surface u201d means the surf..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3b289e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    7143\n",
       "8    7102\n",
       "6    6887\n",
       "2    6816\n",
       "1    6756\n",
       "5    6467\n",
       "3    6059\n",
       "9    5961\n",
       "4    5928\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ab4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array( ['(Human Necessities)',\n",
    " '(Performing Operations; Transporting)',\n",
    " '(Chemistry; Metallurgy)',\n",
    " '(Textiles; Paper)',\n",
    " '(Fixed Constructions)',\n",
    " '(Mechanical Engineering; Lightning; Heating; Weapons; Blasting)',\n",
    " '(Physics)',\n",
    " '(Electricity)', \n",
    " '(General tagging of new or cross-sectional technology)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8a56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(data[\"Content\"].to_numpy(),\n",
    "                                                                            data[\"Label\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64290d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53207, 53207, 5912, 5912)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8be470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['for a multiband operation or in another preferred embodiment the sfc curve such as 25 defines the perimeter of an aperture 33 on the patch 30 fig1 such an aperture contributes significantly to reduce the first resonant frequency of the patch with respect to the solid patch case which significantly contributes to reducing the antenna size said two configurations the sfc slot and the sfc aperture cases can of course be use also with sfc perimeter patch antennas as for instance the one 30 described in fig1 at this point it becomes clear to those skilled in the art what is the scope and spirit of the present invention and that the same sfc geometric principle can be applied in an innovative way to all the well known prior art configurations more examples are given in fig1 16 17 and 18 fig1 describes another preferred embodiment of an sfc antenna it consists on an aperture antenna said aperture being characterized by its sfc perimeter said aperture being impressed over a conducting ground plane or ground counterpoise 34 said ground plane of ground counterpoise consisting for example on a wall of a waveguide or cavity resonator or a part of the structure of a motor vehicle such as a car a lorry an airplane or a tank the aperture can be fed by any of the conventional techniques such as a coaxial cable 11 or a planar microstrip or strip line transmission line to name a few fig1 shows another preferred embodiment where the sfc curves 41 are slotted over a wall of a waveguide 47 of arbitrary cross section this way and slotted waveguide array can be formed with the advantage of the size compressing properties of the sfc curves.',\n",
       "        'may be implemented such a multirange lens is able to alter the peripheral vision and correct astigmatism of the wearer contact lenses such as multirange contact lenses 10 50 and 76 are typically produced as described above by using a transparent material having one refractive index and adjusting curvatures of the zones of the material to form the required different powers transparent materials having variable refractive indices are known in the art such as are used to produce graded index grin lenses and a variable refractive index material may be used to produce a multirange contact lens having powers substantially as described above for lenses 10 50 and 76 all such lenses are assumed to be comprised within the scope of the present invention as will be appreciated by those skilled in the art for any region of a lens using a variable refractive index material the curvature of the zone of the region the base curve and the range and distribution of the refractive index of the material between the zone and the base curve all contribute to the overall power generated for the region it will thus be appreciated that the power of any specific zone the base curve and the transparent material.'],\n",
       "       dtype=object),\n",
       " array([8, 7], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:2], train_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c06051c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc63e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 40000 # max number of words to have in our vocabulary\n",
    "max_length = 250 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a015a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.embedding.Embedding at 0x1c2d034d3d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d68c4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
    "# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n",
    "\n",
    "# Use the default TextVectorization variables\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
    "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d04b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00923051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b4a0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "160 may be adapted to emit gamma rays x rays and or beta electrons i e radiation having an energy of at least 10 kev for some applications the radiation source 166 666 may comprise a radioisotope or a miniature radiation generator in some aspects of the disclosure radiation source 166 666 may comprise a miniature x ray generator such as those described in one or more of the following references u s pat nos 6 134 300 and 6 353 658 to trebes et al haga a et al u201c a miniature x ray tube u201d applied physics letters 84 12 2208 2210 2004 and gutman g et al u201c a novel needle based miniature x ray generating system u201d phys med biol 49 4677 4688 2004 such a miniature x ray generator or x ray tube may be used for radiation source 160 instead of a radioisotope to illuminate the colon contents with x ray photons turning such a generator on and off as needed typically reduces exposure of the subject to radiation in addition the energy range can be better controlled and the flux may be higher for the on periods without increasing subject total exposure it should be appreciated that the capsule 150 350 450 550 650 may include more than one radiation source 166 666 according to various aspects the capsule 150 350 450 550 650 may comprise one or more gamma and or x ray radiation sources and or sources.      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 250, 128), dtype=float32, numpy=\n",
       "array([[[ 0.01806576,  0.02335675, -0.03543026, ...,  0.02876968,\n",
       "         -0.01658437, -0.0295394 ],\n",
       "        [-0.03650651,  0.00482059, -0.02782421, ...,  0.02590832,\n",
       "          0.03077591,  0.03695971],\n",
       "        [ 0.01195394,  0.04461259, -0.03121606, ..., -0.02294071,\n",
       "         -0.00552863, -0.00550319],\n",
       "        ...,\n",
       "        [-0.04878985, -0.01759648,  0.00754996, ...,  0.02724595,\n",
       "         -0.01447652,  0.01962836],\n",
       "        [-0.04878985, -0.01759648,  0.00754996, ...,  0.02724595,\n",
       "         -0.01447652,  0.01962836],\n",
       "        [-0.04878985, -0.01759648,  0.00754996, ...,  0.02724595,\n",
       "         -0.01447652,  0.01962836]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92631433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([ 0.01806576,  0.02335675, -0.03543026,  0.00855614, -0.01487461,\n",
       "       -0.03346654, -0.02609272,  0.01962258, -0.00047801, -0.03228524,\n",
       "        0.0408424 ,  0.04085902, -0.01227093,  0.01272079,  0.04537104,\n",
       "        0.04482205, -0.02632936, -0.01151383,  0.03194325,  0.01486267,\n",
       "       -0.01340358,  0.0010277 , -0.03295763,  0.04432202,  0.03986535,\n",
       "       -0.01512183,  0.01447237,  0.00621806,  0.00500212,  0.04285229,\n",
       "       -0.03991324,  0.02679708,  0.04437294,  0.02314297, -0.04993096,\n",
       "        0.0444879 ,  0.01923313,  0.0272801 , -0.03394802,  0.03073938,\n",
       "        0.03294093, -0.0441174 , -0.00696136,  0.0152172 , -0.03588456,\n",
       "       -0.00949164,  0.04743078,  0.02619446, -0.01028751, -0.03720381,\n",
       "       -0.01398472,  0.03400728,  0.01353718,  0.0476563 , -0.01170985,\n",
       "        0.01044494,  0.00251566, -0.00689371, -0.04853014, -0.03076999,\n",
       "       -0.02821724, -0.01975433,  0.0031889 , -0.01764878,  0.04714047,\n",
       "       -0.03169402, -0.0429983 ,  0.01231652, -0.03357911, -0.00514313,\n",
       "        0.00455267,  0.02721271,  0.03287229, -0.00956138, -0.00443   ,\n",
       "        0.04710597,  0.00120951, -0.02334077, -0.04709587,  0.00186224,\n",
       "       -0.03617125,  0.04116   , -0.04563352, -0.040135  , -0.01645647,\n",
       "        0.03195307,  0.04271908,  0.02791731,  0.00962927, -0.01656858,\n",
       "       -0.04144002, -0.00732021, -0.04578531,  0.01631892, -0.0476824 ,\n",
       "        0.03518007,  0.01137984,  0.04135889,  0.04486931, -0.04982556,\n",
       "        0.00425135, -0.01001638, -0.04044162,  0.03982652, -0.01060507,\n",
       "        0.00366614, -0.00907836, -0.04961374,  0.01747575,  0.00022034,\n",
       "       -0.00051726,  0.02207511, -0.04694283, -0.04484374, -0.02132125,\n",
       "       -0.04773779,  0.0201103 ,  0.02804709, -0.03890546,  0.01101875,\n",
       "       -0.02903891, -0.03745438,  0.03248985,  0.02396444, -0.02899591,\n",
       "        0.02876968, -0.01658437, -0.0295394 ], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f2ea2",
   "metadata": {},
   "source": [
    "More specifically, we'll be building the following:\n",
    "* **Model 0**: Naive Bayes (baseline)\n",
    "* **Model 1**: Feed-forward neural network (dense model)\n",
    "* **Model 2**: LSTM model\n",
    "* **Model 3**: GRU model\n",
    "* **Model 4**: Bidirectional-LSTM model\n",
    "* **Model 5**: 1D Convolutional Neural Network\n",
    "* **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
    "* **Model 7**: Same as model 6 with 10% of training data\n",
    "\n",
    "Model 0 is the simplest to acquire a baseline which we'll expect each other of the other deeper models to beat.\n",
    "\n",
    "Each experiment will go through the following steps:\n",
    "* Construct the model\n",
    "* Train the model\n",
    "* Make predictions with the model\n",
    "* Track prediction evaluation metrics for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d33b8496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4c6340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 51.91%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d913ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 5, 2, 2, 7, 1, 1, 8, 5, 8, 7, 2, 5, 3, 4, 8, 2, 7, 7],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051479bd",
   "metadata": {},
   "source": [
    "### Creating an evaluation function for our model experiments\n",
    "\n",
    "We could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score\n",
    "\n",
    "> 🔑 **Note:** Since we're dealing with a classification problem, the above metrics are the most appropriate. If we were working with a regression problem, other metrics such as MAE (mean absolute error) would be a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da02a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8358e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 51.911366711772665,\n",
       " 'precision': 0.5435636745764952,\n",
       " 'recall': 0.5191136671177267,\n",
       " 'f1': 0.491364899712393}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50df0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "859e84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "  \"\"\"\n",
    "  Creates a TensorBoard callback instand to store log files.\n",
    "\n",
    "  Stores log files with the filepath:\n",
    "    \"dir_name/experiment_name/current_datetime/\"\n",
    "\n",
    "  Args:\n",
    "    dir_name: target directory to store TensorBoard log files\n",
    "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
    "  \"\"\"\n",
    "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "  )\n",
    "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "  return tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb0f5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c2034e",
   "metadata": {},
   "source": [
    "Machinehack competitions download - Data Science Student Championship 2024\n",
    "Data Dictionary:\n",
    "\n",
    "Abstract (59119 rows): A summary of the patent.\n",
    "\n",
    "Label (9 classes): The patent classification according to the European Patent Office (EPO) classification scheme.\n",
    "\n",
    "Categories:\n",
    "\n",
    "1 (Human Necessities),\n",
    "2 (Performing Operations; Transporting),\n",
    "3 (Chemistry; Metallurgy),\n",
    "4 (Textiles; Paper),\n",
    "5 (Fixed Constructions),\n",
    "6 (Mechanical Engineering; Lightning; Heating; Weapons; Blasting),\n",
    "7 (Physics),\n",
    "8 (Electricity), and\n",
    "9 (General tagging of new or cross-sectional technology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "808edf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x) # create an embedding of the numerized numbers\n",
    "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x) # create the output layer, want more than 2 outputs so use softmax activation\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3bfd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f980c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (Text  (None, 250)               0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 250, 128)          5120000   \n",
      "                                                                 \n",
      " global_average_pooling1d_2  (None, 128)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5121290 (19.54 MB)\n",
      "Trainable params: 5121290 (19.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e98ce541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/simple_dense_model/20240331-033226\n",
      "Epoch 1/5\n",
      "1663/1663 [==============================] - 148s 89ms/step - loss: 1.7518 - accuracy: 0.4151 - val_loss: 1.4863 - val_accuracy: 0.5085\n",
      "Epoch 2/5\n",
      "1663/1663 [==============================] - 146s 88ms/step - loss: 1.3323 - accuracy: 0.5579 - val_loss: 1.3353 - val_accuracy: 0.5524\n",
      "Epoch 3/5\n",
      "1663/1663 [==============================] - 142s 86ms/step - loss: 1.1502 - accuracy: 0.6153 - val_loss: 1.2843 - val_accuracy: 0.5700\n",
      "Epoch 4/5\n",
      "1663/1663 [==============================] - 140s 84ms/step - loss: 1.0194 - accuracy: 0.6598 - val_loss: 1.2751 - val_accuracy: 0.5702\n",
      "Epoch 5/5\n",
      "1663/1663 [==============================] - 152s 91ms/step - loss: 0.9105 - accuracy: 0.6966 - val_loss: 1.2816 - val_accuracy: 0.5653\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
    "                                                                     experiment_name=\"simple_dense_model\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "946a7bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 6ms/step - loss: 1.2816 - accuracy: 0.5653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2815651893615723, 0.5652909278869629]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f46ed36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 5, 5, 4, 4, 7, 1, 1, 8, 5, 8, 7, 2, 1, 3, 4, 8, 2, 7, 7],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (these come back in the form of probabilities)\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "# Turn prediction probabilities into single-dimension tensor of floats\n",
    "model_1_preds = model_1_pred_probs.argmax(axis=1) # squeeze removes single dimensions\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42cb30a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 56.529093369418135,\n",
       " 'precision': 0.5437580537489468,\n",
       " 'recall': 0.5652909336941814,\n",
       " 'f1': 0.5505000571342245}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 metrics\n",
    "model_1_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "531854cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 51.91, New accuracy: 56.53, Difference: 4.62\n",
      "Baseline precision: 0.54, New precision: 0.54, Difference: 0.00\n",
      "Baseline recall: 0.52, New recall: 0.57, Difference: 0.05\n",
      "Baseline f1: 0.49, New f1: 0.55, Difference: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Create a helper function to compare our baseline results to new model results\n",
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
    "                                new_model_results=model_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82cf84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
